{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmartParking(Third model).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TbfjumaUKsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcVsOb9qGVHK",
        "colab_type": "text"
      },
      "source": [
        "# Get the CNR-EXT dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL-DqMr0LNFh",
        "colab_type": "code",
        "outputId": "7f4a0e3e-e4e9-4eb7-ba6f-19b0038e6896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! wget http://cnrpark.it/dataset/CNR-EXT-Patches-150x150.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-21 16:03:22--  http://cnrpark.it/dataset/CNR-EXT-Patches-150x150.zip\n",
            "Resolving cnrpark.it (cnrpark.it)... 146.48.85.22\n",
            "Connecting to cnrpark.it (cnrpark.it)|146.48.85.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 449502403 (429M) [application/zip]\n",
            "Saving to: ‘CNR-EXT-Patches-150x150.zip’\n",
            "\n",
            "CNR-EXT-Patches-150 100%[===================>] 428.68M  91.8MB/s    in 5.7s    \n",
            "\n",
            "2019-09-21 16:03:28 (75.5 MB/s) - ‘CNR-EXT-Patches-150x150.zip’ saved [449502403/449502403]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWpysLHbOQxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !unzip CNR-EXT-Patches-150x150.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHm2bUeMGdeP",
        "colab_type": "text"
      },
      "source": [
        "#Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpUUO2IZUTgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = pd.read_csv('LABELS/all.txt', delim_whitespace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI5X8uwqbTSg",
        "colab_type": "code",
        "outputId": "14a4873d-fcdc-4c24-f6d0-986a61d4a9fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "for i in range(len(labels)):\n",
        "  if (i % 15000) == 0:\n",
        "    print(i)\n",
        "  oldPath = 'PATCHES/'+ labels.iloc[i, 0];\n",
        "  newPath1 = 'data/train/full/%d.jpg' % (i,)\n",
        "  newPath2 = 'data/train/free/%d.jpg' % (i,)\n",
        "  newPath3 = 'data/val/full/%d.jpg' % (i,)\n",
        "  newPath4 = 'data/val/free/%d.jpg' % (i,)\n",
        "  if random.randint(0, 1):\n",
        "    continue\n",
        "  if(labels.iloc[i, 1]):\n",
        "    if random.randint(0, 1) or random.randint(0, 1):\n",
        "      shutil.move(oldPath, newPath1)\n",
        "    else:\n",
        "      shutil.move(oldPath, newPath3)\n",
        "  else :\n",
        "    if random.randint(0, 1) or random.randint(0, 1):\n",
        "      shutil.move(oldPath, newPath2)\n",
        "    else:\n",
        "      shutil.move(oldPath, newPath4)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "15000\n",
            "30000\n",
            "45000\n",
            "60000\n",
            "75000\n",
            "90000\n",
            "105000\n",
            "120000\n",
            "135000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067v0MVEzSmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHePwXkhzb9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify transforms using torchvision.transforms as transforms\n",
        "# library\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(75),\n",
        "    transforms.CenterCrop(75),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRwpcDduzppd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in each dataset and apply transformations using\n",
        "# the torchvision.datasets as datasets library\n",
        "train_data = datasets.ImageFolder(\"data/train\", transform = transformations)\n",
        "test_data = datasets.ImageFolder(\"data/val\", transform = transformations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHATa7i66pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "                        train_data,\n",
        "                        batch_size=30,\n",
        "                        shuffle=True,\n",
        "                        num_workers=4,\n",
        "                        pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "                        test_data,\n",
        "                        batch_size=10,\n",
        "                        shuffle=False,\n",
        "                        num_workers=4,\n",
        "                        pin_memory=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQw2bHlsF7dY",
        "colab_type": "text"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NvrCsVq8SYR",
        "colab_type": "code",
        "outputId": "37fad544-ebe2-4f1a-8f62-0fc5d3cef1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Find the device available to use using torch library\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Move model to the device specified above\n",
        "model.to(device)\n",
        "\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e1d708da5d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Move model to the device specified above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1mkT5cVe_1E",
        "colab_type": "text"
      },
      "source": [
        "# squeeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHs9qZyGbg2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of classes in the dataset\n",
        "num_of_output_classes = 2\n",
        "\n",
        "# HYPER-PARAMETERS\n",
        "\n",
        "train_only_last_layer = False # boolean variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOaPoekObtgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some variables storing dataset info\n",
        "dset_sizes = {} # empty dict\n",
        "dset_sizes['train'] = len(train_data)\n",
        "dset_sizes['val'] = len(test_data)\n",
        "dset_classes = train_data.classes # number of classes in datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icMzCW7lb5Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on GPU if CUDA is available\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "\"\"\"Use this if you want to visualise the dataset before training\"\"\"\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "# imshow(out, title=[dset_classes[x] for x in classes])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jlDpPDaYCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UTILITY FUNCTIONS HERE.\n",
        "\n",
        "import numpy\n",
        "\n",
        "\n",
        "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
        "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
        "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "\n",
        "    if epoch % lr_decay_epoch == 0:\n",
        "        print('LR is set to {}'.format(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "# utility function to visualise few images from the dataset\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    plt.imshow(inp)\n",
        "    # if title is not None:\n",
        "        # plt.title(title)\n",
        "    plt.pause(10)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        print(outputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range(inputs.size()[0]):\n",
        "            images_so_far += 1\n",
        "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "            ax.axis('off')\n",
        "            ax.set_title('predicted: {}'.format(dset_classes[labels.data[j]]))\n",
        "            imshow(inputs.cpu().data[j])\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "                return\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model = model\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    \n",
        "    counter = 0\n",
        "    old_loss = 0\n",
        "    epoch = 0\n",
        "    # run for given number of epochs\n",
        "    while epoch <num_epochs:\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        accuracy = 0\n",
        "        \n",
        "        a = numpy.array([[epoch, 1]])\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                optimizer = lr_scheduler(optimizer, epoch)\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            if phase == 'train':\n",
        "                phase_ = train_loader\n",
        "            else:\n",
        "                phase_ = val_loader\n",
        "\n",
        "            # Run through all data in mini batches\n",
        "            for data in phase_:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if use_gpu:\n",
        "                    inputs, labels = Variable(inputs.cuda()), \\\n",
        "                        Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward pass\n",
        "                outputs = model.forward(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "                # calculating the loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    old_loss = running_loss\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # statistics for printing\n",
        "                running_loss += loss.item()*inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                if phase == 'val' :\n",
        "                  # Since our model outputs a LogSoftmax, find the real \n",
        "                  # percentages by reversing the log function\n",
        "                  outputs = torch.exp(outputs)\n",
        "                  # Get the top class of the output\n",
        "                  top_p, top_class = outputs.topk(1, dim=1)\n",
        "                  # See how many of the classes were correct?\n",
        "                  equals = top_class == labels.view(*top_class.shape)\n",
        "                  # Calculate the mean (get the accuracy for this batch)\n",
        "                  # and add it to the running accuracy for this epoch\n",
        "                  accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                \n",
        "                if phase == 'train':\n",
        "                  \n",
        "                  if(counter % 100 == 0) :\n",
        "                    print('{} Training Loss:{:.6f}'.format(counter, running_loss - old_loss))\n",
        "                    a = numpy.append(a, [[counter, (running_loss - old_loss)]], axis = 0)\n",
        "                  counter += 1\n",
        "            \n",
        "            \n",
        "            epoch_loss = running_loss / dset_sizes[phase]\n",
        "            \n",
        "          \n",
        "        epoch_acc = accuracy/len(val_loader)\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "          phase, epoch_loss, epoch_acc))\n",
        "\n",
        "          # save model if it performed better than\n",
        "          # any other previous model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model = copy.deepcopy(model)\n",
        "            \n",
        "        saveToDrive(save_checkpoint(epoch, model, optimizer, epoch_loss, 'squeeze_sgd1_v'))\n",
        "        a = numpy.append(a, [[epoch, epoch_loss]], axis = 0)\n",
        "        a = numpy.append(a, [[epoch, epoch_acc]], axis = 0)\n",
        "        saveCSV('squeeze_sgd1_v{}.csv'.format(epoch), a)\n",
        "        \n",
        "        epoch += 1\n",
        "        \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    return best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzwxZwXbCqO",
        "colab_type": "code",
        "outputId": "11c69bd8-1068-4aef-9ee0-960f4a41a2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import everything\n",
        "from __future__ import print_function, division\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "######################################################################\n",
        "# ConvNet training\n",
        "# ----------------------------------\n",
        "\n",
        "\n",
        "# using the model defined in the beginning of the program\n",
        "# Example: model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "def DefineSqueeze(num_of_output_classes, train_only_last_layer):\n",
        "  # example\n",
        "  import torchvision\n",
        "  model_conv = torchvision.models.squeezenet1_1(pretrained=True) # define model here\n",
        "  \n",
        "  if train_only_last_layer is True:\n",
        "    # turn off backprop update for all the weights in the model\n",
        "    for param in model_conv.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "  # change the last Conv2D layer in case of squeezenet. there is no fc layer in the end.\n",
        "  num_ftrs = 512\n",
        "  model_conv.classifier._modules[\"1\"] = nn.Conv2d(512, num_of_output_classes, kernel_size=(1, 1))\n",
        "  model_conv.classifier._modules[\"2\"] = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  # because in forward pass, there is a view function call which depends on the final output class size.\n",
        "  model_conv.num_classes = num_of_output_classes\n",
        "\n",
        "\n",
        "  model_conv = model_conv.cuda()\n",
        "\n",
        "  # defining loss criterion, for these\n",
        "  # models CrossEntropyLoss works the best\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Observe that only parameters of final layer are being optimized as\n",
        "  # opoosed to before.\n",
        "  \"\"\" Defining an optimiser function here, can use Adam, RMSprop or simple SGD\"\"\"\n",
        "  optimizer_conv = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  return model_conv, optimizer_conv, criterion\n",
        "\n",
        "model_conv, optimizer_conv, criterion = DefineSqueeze(2, False)\n",
        "\n",
        "######################################################################\n",
        "# Train and evaluate\n",
        "# ^^^^^^^^^^^^^^^^^^\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "######################################################################\n",
        "\n",
        "# If we want to visvalise model. then call this function\n",
        "# visualize_model(model_conv)\n",
        "\n",
        "# plt.ioff()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to /root/.cache/torch/checkpoints/squeezenet1_1-f364aa15.pth\n",
            "100%|██████████| 4.74M/4.74M [00:00<00:00, 42.4MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "LR is set to 0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Training Loss:65.376785\n",
            "100 Training Loss:0.144819\n",
            "200 Training Loss:0.124399\n",
            "300 Training Loss:0.092602\n",
            "400 Training Loss:0.523408\n",
            "500 Training Loss:0.327716\n",
            "600 Training Loss:1.379999\n",
            "700 Training Loss:0.988931\n",
            "800 Training Loss:0.001445\n",
            "900 Training Loss:0.015172\n",
            "1000 Training Loss:0.000035\n",
            "1100 Training Loss:0.000815\n",
            "1200 Training Loss:0.001228\n",
            "1300 Training Loss:0.005157\n",
            "1400 Training Loss:0.000472\n",
            "1500 Training Loss:0.002796\n",
            "1600 Training Loss:0.004320\n",
            "1700 Training Loss:0.033428\n",
            "1800 Training Loss:0.062646\n",
            "1900 Training Loss:0.000698\n",
            "2000 Training Loss:0.004780\n",
            "2100 Training Loss:0.005175\n",
            "2200 Training Loss:0.014380\n",
            "2300 Training Loss:0.003256\n",
            "2400 Training Loss:0.558885\n",
            "2500 Training Loss:0.003832\n",
            "2600 Training Loss:0.004766\n",
            "val Loss: 0.0028 Acc: 0.9991\n",
            "Loss 0.002769\n",
            "Epoch 1/24\n",
            "----------\n",
            "2700 Training Loss:0.001963\n",
            "2800 Training Loss:0.011353\n",
            "2900 Training Loss:0.093744\n",
            "3000 Training Loss:0.007809\n",
            "3100 Training Loss:0.009337\n",
            "3200 Training Loss:2.482052\n",
            "3300 Training Loss:0.282200\n",
            "3400 Training Loss:0.000074\n",
            "3500 Training Loss:3.966090\n",
            "3600 Training Loss:0.299824\n",
            "3700 Training Loss:0.016028\n",
            "3800 Training Loss:0.011696\n",
            "3900 Training Loss:0.034010\n",
            "4000 Training Loss:0.017673\n",
            "4100 Training Loss:0.162759\n",
            "4200 Training Loss:0.657311\n",
            "4300 Training Loss:0.011222\n",
            "4400 Training Loss:0.022007\n",
            "4500 Training Loss:0.019481\n",
            "4600 Training Loss:0.000402\n",
            "4700 Training Loss:0.000860\n",
            "4800 Training Loss:0.364577\n",
            "4900 Training Loss:0.000437\n",
            "5000 Training Loss:0.000568\n",
            "5100 Training Loss:0.037786\n",
            "5200 Training Loss:0.188083\n",
            "5300 Training Loss:0.104995\n",
            "val Loss: 0.0016 Acc: 0.9997\n",
            "Loss 0.001552\n",
            "Epoch 2/24\n",
            "----------\n",
            "5400 Training Loss:0.034296\n",
            "5500 Training Loss:0.003754\n",
            "5600 Training Loss:0.000005\n",
            "5700 Training Loss:0.096702\n",
            "5800 Training Loss:0.192390\n",
            "5900 Training Loss:0.000274\n",
            "6000 Training Loss:0.000260\n",
            "6100 Training Loss:0.058478\n",
            "6200 Training Loss:0.009486\n",
            "6300 Training Loss:0.144378\n",
            "6400 Training Loss:0.000041\n",
            "6500 Training Loss:0.153874\n",
            "6600 Training Loss:0.007097\n",
            "6700 Training Loss:0.000211\n",
            "6800 Training Loss:0.010202\n",
            "6900 Training Loss:1.114014\n",
            "7000 Training Loss:0.023893\n",
            "7100 Training Loss:0.004999\n",
            "7200 Training Loss:0.000030\n",
            "7300 Training Loss:0.000046\n",
            "7400 Training Loss:0.000749\n",
            "7500 Training Loss:0.004056\n",
            "7600 Training Loss:0.014752\n",
            "7700 Training Loss:0.004720\n",
            "7800 Training Loss:0.026841\n",
            "7900 Training Loss:2.425535\n",
            "8000 Training Loss:0.000534\n",
            "val Loss: 0.0017 Acc: 0.9996\n",
            "Loss 0.001691\n",
            "Epoch 3/24\n",
            "----------\n",
            "8100 Training Loss:2.601493\n",
            "8200 Training Loss:0.034693\n",
            "8300 Training Loss:0.005944\n",
            "8400 Training Loss:0.000459\n",
            "8500 Training Loss:0.006755\n",
            "8600 Training Loss:0.000190\n",
            "8700 Training Loss:0.155740\n",
            "8800 Training Loss:0.001681\n",
            "8900 Training Loss:0.000284\n",
            "9000 Training Loss:0.005249\n",
            "9100 Training Loss:0.000155\n",
            "9200 Training Loss:0.191206\n",
            "9300 Training Loss:0.000206\n",
            "9400 Training Loss:0.000490\n",
            "9500 Training Loss:1.685011\n",
            "9600 Training Loss:0.002911\n",
            "9700 Training Loss:0.000044\n",
            "9800 Training Loss:0.000215\n",
            "9900 Training Loss:0.001206\n",
            "10000 Training Loss:0.001194\n",
            "10100 Training Loss:0.090998\n",
            "10200 Training Loss:0.420078\n",
            "10300 Training Loss:0.002240\n",
            "10400 Training Loss:0.001327\n",
            "10500 Training Loss:0.007499\n",
            "10600 Training Loss:0.000078\n",
            "10700 Training Loss:0.007351\n",
            "val Loss: 0.0019 Acc: 0.9997\n",
            "Loss 0.001862\n",
            "Epoch 4/24\n",
            "----------\n",
            "10800 Training Loss:0.003787\n",
            "10900 Training Loss:0.000803\n",
            "11000 Training Loss:0.000061\n",
            "11100 Training Loss:0.000012\n",
            "11200 Training Loss:0.000185\n",
            "11300 Training Loss:0.000059\n",
            "11400 Training Loss:0.004681\n",
            "11500 Training Loss:0.000705\n",
            "11600 Training Loss:0.001019\n",
            "11700 Training Loss:0.005900\n",
            "11800 Training Loss:0.001202\n",
            "11900 Training Loss:0.000069\n",
            "12000 Training Loss:0.010031\n",
            "12100 Training Loss:0.000806\n",
            "12200 Training Loss:0.000133\n",
            "12300 Training Loss:0.000087\n",
            "12400 Training Loss:0.000124\n",
            "12500 Training Loss:0.003222\n",
            "12600 Training Loss:0.005416\n",
            "12700 Training Loss:0.000016\n",
            "12800 Training Loss:0.005574\n",
            "12900 Training Loss:0.000037\n",
            "13000 Training Loss:0.002517\n",
            "13100 Training Loss:0.520928\n",
            "13200 Training Loss:0.174722\n",
            "13300 Training Loss:0.002619\n",
            "13400 Training Loss:0.000225\n",
            "val Loss: 0.0020 Acc: 0.9997\n",
            "Loss 0.001997\n",
            "Epoch 5/24\n",
            "----------\n",
            "13500 Training Loss:0.028880\n",
            "13600 Training Loss:0.003250\n",
            "13700 Training Loss:0.001008\n",
            "13800 Training Loss:0.000012\n",
            "13900 Training Loss:0.000014\n",
            "14000 Training Loss:0.011628\n",
            "14100 Training Loss:0.000128\n",
            "14200 Training Loss:0.000342\n",
            "14300 Training Loss:0.000018\n",
            "14400 Training Loss:4.536068\n",
            "14500 Training Loss:0.000010\n",
            "14600 Training Loss:0.000483\n",
            "14700 Training Loss:0.004712\n",
            "14800 Training Loss:0.017787\n",
            "14900 Training Loss:0.000398\n",
            "15000 Training Loss:0.006924\n",
            "15100 Training Loss:0.010685\n",
            "15200 Training Loss:0.000008\n",
            "15300 Training Loss:0.004928\n",
            "15400 Training Loss:1.120547\n",
            "15500 Training Loss:0.000001\n",
            "15600 Training Loss:0.000218\n",
            "15700 Training Loss:0.001305\n",
            "15800 Training Loss:0.002833\n",
            "15900 Training Loss:0.000199\n",
            "16000 Training Loss:0.007289\n",
            "16100 Training Loss:0.049609\n",
            "val Loss: 0.0012 Acc: 0.9997\n",
            "Loss 0.001235\n",
            "Epoch 6/24\n",
            "----------\n",
            "16200 Training Loss:0.070104\n",
            "16300 Training Loss:0.143158\n",
            "16400 Training Loss:0.000002\n",
            "16500 Training Loss:0.006828\n",
            "16600 Training Loss:0.000016\n",
            "16700 Training Loss:0.010707\n",
            "16800 Training Loss:0.262484\n",
            "16900 Training Loss:0.072443\n",
            "17000 Training Loss:0.001017\n",
            "17100 Training Loss:0.001009\n",
            "17200 Training Loss:0.000124\n",
            "17300 Training Loss:0.005384\n",
            "17400 Training Loss:0.005770\n",
            "17500 Training Loss:11.670831\n",
            "17600 Training Loss:0.010651\n",
            "17700 Training Loss:0.000023\n",
            "17800 Training Loss:0.000051\n",
            "17900 Training Loss:0.000090\n",
            "18000 Training Loss:0.000003\n",
            "18100 Training Loss:0.040481\n",
            "18200 Training Loss:0.000002\n",
            "18300 Training Loss:0.000023\n",
            "18400 Training Loss:0.000180\n",
            "18500 Training Loss:0.001401\n",
            "18600 Training Loss:0.064978\n",
            "18700 Training Loss:0.013866\n",
            "val Loss: 0.0015 Acc: 0.9997\n",
            "Loss 0.001474\n",
            "Epoch 7/24\n",
            "----------\n",
            "LR is set to 0.0001\n",
            "18800 Training Loss:0.002881\n",
            "18900 Training Loss:0.001789\n",
            "19000 Training Loss:0.000001\n",
            "19100 Training Loss:0.018875\n",
            "19200 Training Loss:0.000085\n",
            "19300 Training Loss:0.005411\n",
            "19400 Training Loss:0.002360\n",
            "19500 Training Loss:0.000029\n",
            "19600 Training Loss:0.000006\n",
            "19700 Training Loss:0.023504\n",
            "19800 Training Loss:0.000292\n",
            "19900 Training Loss:0.578510\n",
            "20000 Training Loss:0.000741\n",
            "20100 Training Loss:0.001801\n",
            "20200 Training Loss:0.004299\n",
            "20300 Training Loss:0.000045\n",
            "20400 Training Loss:0.000106\n",
            "20500 Training Loss:0.086277\n",
            "20600 Training Loss:0.000659\n",
            "20700 Training Loss:0.002911\n",
            "20800 Training Loss:0.008915\n",
            "20900 Training Loss:0.007798\n",
            "21000 Training Loss:0.000001\n",
            "21100 Training Loss:0.000782\n",
            "21200 Training Loss:0.000184\n",
            "21300 Training Loss:0.002460\n",
            "21400 Training Loss:0.000210\n",
            "val Loss: 0.0014 Acc: 0.9996\n",
            "Loss 0.001409\n",
            "Epoch 8/24\n",
            "----------\n",
            "21500 Training Loss:0.011989\n",
            "21600 Training Loss:0.010707\n",
            "21700 Training Loss:0.000032\n",
            "21800 Training Loss:0.252954\n",
            "21900 Training Loss:0.000877\n",
            "22000 Training Loss:0.001096\n",
            "22100 Training Loss:0.000141\n",
            "22200 Training Loss:0.048088\n",
            "22300 Training Loss:0.461665\n",
            "22400 Training Loss:0.000348\n",
            "22500 Training Loss:0.006819\n",
            "22600 Training Loss:0.000518\n",
            "22700 Training Loss:0.004515\n",
            "22800 Training Loss:2.472605\n",
            "22900 Training Loss:0.001976\n",
            "23000 Training Loss:0.000826\n",
            "23100 Training Loss:0.411234\n",
            "23200 Training Loss:0.000609\n",
            "23300 Training Loss:0.006882\n",
            "23400 Training Loss:0.000005\n",
            "23500 Training Loss:0.048651\n",
            "23600 Training Loss:0.029796\n",
            "23700 Training Loss:0.000583\n",
            "23800 Training Loss:0.014099\n",
            "23900 Training Loss:0.000447\n",
            "24000 Training Loss:0.000250\n",
            "24100 Training Loss:0.017221\n",
            "val Loss: 0.0011 Acc: 0.9997\n",
            "Loss 0.001095\n",
            "Epoch 9/24\n",
            "----------\n",
            "24200 Training Loss:0.039325\n",
            "24300 Training Loss:0.000008\n",
            "24400 Training Loss:0.000732\n",
            "24500 Training Loss:0.000125\n",
            "24600 Training Loss:0.006810\n",
            "24700 Training Loss:0.002229\n",
            "24800 Training Loss:0.000000\n",
            "24900 Training Loss:0.004993\n",
            "25000 Training Loss:0.017695\n",
            "25100 Training Loss:0.000099\n",
            "25200 Training Loss:0.001318\n",
            "25300 Training Loss:0.000041\n",
            "25400 Training Loss:0.025131\n",
            "25500 Training Loss:0.565114\n",
            "25600 Training Loss:0.000002\n",
            "25700 Training Loss:0.001261\n",
            "25800 Training Loss:0.000041\n",
            "25900 Training Loss:0.000422\n",
            "26000 Training Loss:0.005431\n",
            "26100 Training Loss:0.000822\n",
            "26200 Training Loss:0.004976\n",
            "26300 Training Loss:0.015552\n",
            "26400 Training Loss:0.001563\n",
            "26500 Training Loss:0.169234\n",
            "26600 Training Loss:0.000099\n",
            "26700 Training Loss:0.191375\n",
            "26800 Training Loss:0.000918\n",
            "val Loss: 0.0010 Acc: 0.9998\n",
            "Loss 0.000977\n",
            "Epoch 10/24\n",
            "----------\n",
            "26900 Training Loss:0.000206\n",
            "27000 Training Loss:0.025264\n",
            "27100 Training Loss:0.141802\n",
            "27200 Training Loss:0.000008\n",
            "27300 Training Loss:0.000218\n",
            "27400 Training Loss:0.000177\n",
            "27500 Training Loss:0.000243\n",
            "27600 Training Loss:0.007150\n",
            "27700 Training Loss:0.001311\n",
            "27800 Training Loss:0.003623\n",
            "27900 Training Loss:0.000117\n",
            "28000 Training Loss:0.101802\n",
            "28100 Training Loss:0.003204\n",
            "28200 Training Loss:0.029201\n",
            "28300 Training Loss:0.000407\n",
            "28400 Training Loss:0.017365\n",
            "28500 Training Loss:0.002246\n",
            "28600 Training Loss:0.000004\n",
            "28700 Training Loss:0.000025\n",
            "28800 Training Loss:0.000003\n",
            "28900 Training Loss:0.070601\n",
            "29000 Training Loss:0.000380\n",
            "29100 Training Loss:0.006246\n",
            "29200 Training Loss:0.003898\n",
            "29300 Training Loss:0.001284\n",
            "29400 Training Loss:0.003748\n",
            "29500 Training Loss:0.000582\n",
            "val Loss: 0.0009 Acc: 0.9998\n",
            "Loss 0.000919\n",
            "Epoch 11/24\n",
            "----------\n",
            "29600 Training Loss:0.001344\n",
            "29700 Training Loss:0.012767\n",
            "29800 Training Loss:0.000074\n",
            "29900 Training Loss:0.011426\n",
            "30000 Training Loss:0.002497\n",
            "30100 Training Loss:0.001738\n",
            "30200 Training Loss:0.001512\n",
            "30300 Training Loss:0.004206\n",
            "30400 Training Loss:0.001239\n",
            "30500 Training Loss:0.004485\n",
            "30600 Training Loss:0.000011\n",
            "30700 Training Loss:0.000500\n",
            "30800 Training Loss:0.000008\n",
            "30900 Training Loss:0.003944\n",
            "31000 Training Loss:0.001555\n",
            "31100 Training Loss:0.043461\n",
            "31200 Training Loss:0.002945\n",
            "31300 Training Loss:0.000378\n",
            "31400 Training Loss:0.067389\n",
            "31500 Training Loss:0.000042\n",
            "31600 Training Loss:0.007482\n",
            "31700 Training Loss:0.201222\n",
            "31800 Training Loss:0.000000\n",
            "31900 Training Loss:0.000909\n",
            "32000 Training Loss:0.000358\n",
            "32100 Training Loss:0.002056\n",
            "32200 Training Loss:0.010487\n",
            "val Loss: 0.0010 Acc: 0.9999\n",
            "Loss 0.000966\n",
            "Epoch 12/24\n",
            "----------\n",
            "32300 Training Loss:0.000788\n",
            "32400 Training Loss:0.002106\n",
            "32500 Training Loss:0.000000\n",
            "32600 Training Loss:0.000082\n",
            "32700 Training Loss:0.000404\n",
            "32800 Training Loss:0.002094\n",
            "32900 Training Loss:0.010975\n",
            "33000 Training Loss:0.001757\n",
            "33100 Training Loss:0.000050\n",
            "33200 Training Loss:0.106399\n",
            "33300 Training Loss:0.013396\n",
            "33400 Training Loss:0.029013\n",
            "33500 Training Loss:0.000190\n",
            "33600 Training Loss:0.001170\n",
            "33700 Training Loss:0.000028\n",
            "33800 Training Loss:0.004760\n",
            "33900 Training Loss:0.009255\n",
            "34000 Training Loss:0.001761\n",
            "34100 Training Loss:0.001130\n",
            "34200 Training Loss:0.001448\n",
            "34300 Training Loss:0.001411\n",
            "34400 Training Loss:0.000364\n",
            "34500 Training Loss:0.007271\n",
            "34600 Training Loss:0.012492\n",
            "34700 Training Loss:0.000801\n",
            "34800 Training Loss:0.000973\n",
            "34900 Training Loss:0.003044\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000917\n",
            "Epoch 13/24\n",
            "----------\n",
            "35000 Training Loss:0.000072\n",
            "35100 Training Loss:0.004101\n",
            "35200 Training Loss:0.000496\n",
            "35300 Training Loss:0.000489\n",
            "35400 Training Loss:0.000424\n",
            "35500 Training Loss:0.603748\n",
            "35600 Training Loss:0.005714\n",
            "35700 Training Loss:0.007373\n",
            "35800 Training Loss:0.000003\n",
            "35900 Training Loss:0.000284\n",
            "36000 Training Loss:0.178544\n",
            "36100 Training Loss:0.000448\n",
            "36200 Training Loss:0.005436\n",
            "36300 Training Loss:0.001177\n",
            "36400 Training Loss:0.001766\n",
            "36500 Training Loss:0.000084\n",
            "36600 Training Loss:0.000863\n",
            "36700 Training Loss:0.004404\n",
            "36800 Training Loss:0.019314\n",
            "36900 Training Loss:0.001560\n",
            "37000 Training Loss:0.000695\n",
            "37100 Training Loss:0.000512\n",
            "37200 Training Loss:0.003907\n",
            "37300 Training Loss:0.001566\n",
            "37400 Training Loss:0.000033\n",
            "37500 Training Loss:0.000563\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000862\n",
            "Epoch 14/24\n",
            "----------\n",
            "LR is set to 1.0000000000000003e-05\n",
            "37600 Training Loss:0.000396\n",
            "37700 Training Loss:0.009238\n",
            "37800 Training Loss:0.116963\n",
            "37900 Training Loss:0.000319\n",
            "38000 Training Loss:0.000571\n",
            "38100 Training Loss:0.027664\n",
            "38200 Training Loss:0.001044\n",
            "38300 Training Loss:0.000885\n",
            "38400 Training Loss:0.003365\n",
            "38500 Training Loss:0.003580\n",
            "38600 Training Loss:0.001748\n",
            "38700 Training Loss:0.137439\n",
            "38800 Training Loss:0.000119\n",
            "38900 Training Loss:0.000465\n",
            "39000 Training Loss:0.008450\n",
            "39100 Training Loss:0.001295\n",
            "39200 Training Loss:0.000018\n",
            "39300 Training Loss:0.000038\n",
            "39400 Training Loss:0.308415\n",
            "39500 Training Loss:0.087973\n",
            "39600 Training Loss:0.001910\n",
            "39700 Training Loss:0.008646\n",
            "39800 Training Loss:0.000489\n",
            "39900 Training Loss:0.004296\n",
            "40000 Training Loss:0.000428\n",
            "40100 Training Loss:0.005558\n",
            "40200 Training Loss:0.020872\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000876\n",
            "Epoch 15/24\n",
            "----------\n",
            "40300 Training Loss:0.002066\n",
            "40400 Training Loss:0.000084\n",
            "40500 Training Loss:0.005140\n",
            "40600 Training Loss:0.000145\n",
            "40700 Training Loss:0.000208\n",
            "40800 Training Loss:0.001568\n",
            "40900 Training Loss:0.004092\n",
            "41000 Training Loss:0.001009\n",
            "41100 Training Loss:0.002720\n",
            "41200 Training Loss:0.057379\n",
            "41300 Training Loss:0.000002\n",
            "41400 Training Loss:0.458052\n",
            "41500 Training Loss:0.001826\n",
            "41600 Training Loss:0.206722\n",
            "41700 Training Loss:0.057910\n",
            "41800 Training Loss:0.004234\n",
            "41900 Training Loss:0.005773\n",
            "42000 Training Loss:0.003844\n",
            "42100 Training Loss:0.000146\n",
            "42200 Training Loss:0.009700\n",
            "42300 Training Loss:0.000018\n",
            "42400 Training Loss:0.002194\n",
            "42500 Training Loss:0.002023\n",
            "42600 Training Loss:0.025411\n",
            "42700 Training Loss:0.002380\n",
            "42800 Training Loss:0.000562\n",
            "42900 Training Loss:0.003891\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000858\n",
            "Epoch 16/24\n",
            "----------\n",
            "43000 Training Loss:0.005252\n",
            "43100 Training Loss:0.005535\n",
            "43200 Training Loss:0.005983\n",
            "43300 Training Loss:0.000283\n",
            "43400 Training Loss:0.000376\n",
            "43500 Training Loss:0.000023\n",
            "43600 Training Loss:0.002474\n",
            "43700 Training Loss:0.001992\n",
            "43800 Training Loss:0.000484\n",
            "43900 Training Loss:0.000048\n",
            "44000 Training Loss:0.008111\n",
            "44100 Training Loss:0.000438\n",
            "44200 Training Loss:0.007633\n",
            "44300 Training Loss:0.000029\n",
            "44400 Training Loss:0.007925\n",
            "44500 Training Loss:0.017674\n",
            "44600 Training Loss:0.000017\n",
            "44700 Training Loss:0.000001\n",
            "44800 Training Loss:0.001778\n",
            "44900 Training Loss:0.026388\n",
            "45000 Training Loss:0.000229\n",
            "45100 Training Loss:0.003864\n",
            "45200 Training Loss:0.038044\n",
            "45300 Training Loss:0.001737\n",
            "45400 Training Loss:0.001252\n",
            "45500 Training Loss:0.000210\n",
            "45600 Training Loss:0.000565\n",
            "val Loss: 0.0008 Acc: 0.9999\n",
            "Loss 0.000848\n",
            "Epoch 17/24\n",
            "----------\n",
            "45700 Training Loss:0.009600\n",
            "45800 Training Loss:0.167396\n",
            "45900 Training Loss:0.000422\n",
            "46000 Training Loss:0.000085\n",
            "46100 Training Loss:0.015869\n",
            "46200 Training Loss:0.299620\n",
            "46300 Training Loss:0.000000\n",
            "46400 Training Loss:0.000025\n",
            "46500 Training Loss:0.008458\n",
            "46600 Training Loss:0.000059\n",
            "46700 Training Loss:0.002341\n",
            "46800 Training Loss:0.004739\n",
            "46900 Training Loss:0.000449\n",
            "47000 Training Loss:0.000149\n",
            "47100 Training Loss:0.155450\n",
            "47200 Training Loss:0.002266\n",
            "47300 Training Loss:0.000000\n",
            "47400 Training Loss:0.001820\n",
            "47500 Training Loss:0.002036\n",
            "47600 Training Loss:0.000085\n",
            "47700 Training Loss:0.003830\n",
            "47800 Training Loss:0.004971\n",
            "47900 Training Loss:0.000009\n",
            "48000 Training Loss:0.000057\n",
            "48100 Training Loss:0.001677\n",
            "48200 Training Loss:0.000024\n",
            "48300 Training Loss:0.000992\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000871\n",
            "Epoch 18/24\n",
            "----------\n",
            "48400 Training Loss:0.014651\n",
            "48500 Training Loss:0.000017\n",
            "48600 Training Loss:0.001209\n",
            "48700 Training Loss:0.607559\n",
            "48800 Training Loss:0.000028\n",
            "48900 Training Loss:0.000879\n",
            "49000 Training Loss:0.000959\n",
            "49100 Training Loss:0.023823\n",
            "49200 Training Loss:0.000013\n",
            "49300 Training Loss:0.007766\n",
            "49400 Training Loss:0.010310\n",
            "49500 Training Loss:0.209562\n",
            "49600 Training Loss:0.000675\n",
            "49700 Training Loss:0.000516\n",
            "49800 Training Loss:0.017952\n",
            "49900 Training Loss:0.000038\n",
            "50000 Training Loss:0.000013\n",
            "50100 Training Loss:0.000170\n",
            "50200 Training Loss:0.006128\n",
            "50300 Training Loss:0.000009\n",
            "50400 Training Loss:0.047347\n",
            "50500 Training Loss:0.000248\n",
            "50600 Training Loss:0.000018\n",
            "50700 Training Loss:0.011222\n",
            "50800 Training Loss:0.000193\n",
            "50900 Training Loss:0.007095\n",
            "51000 Training Loss:0.010225\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000862\n",
            "Epoch 19/24\n",
            "----------\n",
            "51100 Training Loss:0.007753\n",
            "51200 Training Loss:0.020464\n",
            "51300 Training Loss:0.000001\n",
            "51400 Training Loss:0.004436\n",
            "51500 Training Loss:0.000044\n",
            "51600 Training Loss:0.000251\n",
            "51700 Training Loss:0.008616\n",
            "51800 Training Loss:0.001419\n",
            "51900 Training Loss:0.021168\n",
            "52000 Training Loss:0.000001\n",
            "52100 Training Loss:0.040205\n",
            "52200 Training Loss:0.017849\n",
            "52300 Training Loss:0.000435\n",
            "52400 Training Loss:0.005683\n",
            "52500 Training Loss:0.002275\n",
            "52600 Training Loss:0.000570\n",
            "52700 Training Loss:0.000180\n",
            "52800 Training Loss:0.000997\n",
            "52900 Training Loss:0.004196\n",
            "53000 Training Loss:0.085118\n",
            "53100 Training Loss:0.000382\n",
            "53200 Training Loss:0.000082\n",
            "53300 Training Loss:0.000730\n",
            "53400 Training Loss:0.000225\n",
            "53500 Training Loss:0.001748\n",
            "53600 Training Loss:0.091349\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000852\n",
            "Epoch 20/24\n",
            "----------\n",
            "53700 Training Loss:0.010195\n",
            "53800 Training Loss:0.000520\n",
            "53900 Training Loss:0.000160\n",
            "54000 Training Loss:0.000733\n",
            "54100 Training Loss:0.000000\n",
            "54200 Training Loss:0.000203\n",
            "54300 Training Loss:0.000100\n",
            "54400 Training Loss:0.218714\n",
            "54500 Training Loss:0.003836\n",
            "54600 Training Loss:0.002331\n",
            "54700 Training Loss:0.012477\n",
            "54800 Training Loss:0.009269\n",
            "54900 Training Loss:0.010663\n",
            "55000 Training Loss:0.001854\n",
            "55100 Training Loss:0.000289\n",
            "55200 Training Loss:0.006944\n",
            "55300 Training Loss:0.001612\n",
            "55400 Training Loss:0.436794\n",
            "55500 Training Loss:0.026377\n",
            "55600 Training Loss:0.000007\n",
            "55700 Training Loss:0.000071\n",
            "55800 Training Loss:0.000603\n",
            "55900 Training Loss:0.002726\n",
            "56000 Training Loss:0.007149\n",
            "56100 Training Loss:0.024247\n",
            "56200 Training Loss:0.203431\n",
            "56300 Training Loss:0.002146\n",
            "val Loss: 0.0008 Acc: 0.9999\n",
            "Loss 0.000848\n",
            "Epoch 21/24\n",
            "----------\n",
            "LR is set to 1.0000000000000002e-06\n",
            "56400 Training Loss:0.000006\n",
            "56500 Training Loss:0.000033\n",
            "56600 Training Loss:0.000582\n",
            "56700 Training Loss:0.000094\n",
            "56800 Training Loss:0.201477\n",
            "56900 Training Loss:0.000081\n",
            "57000 Training Loss:0.000669\n",
            "57100 Training Loss:0.000047\n",
            "57200 Training Loss:0.000054\n",
            "57300 Training Loss:0.009017\n",
            "57400 Training Loss:0.013869\n",
            "57500 Training Loss:0.000547\n",
            "57600 Training Loss:0.000388\n",
            "57700 Training Loss:0.000003\n",
            "57800 Training Loss:0.000102\n",
            "57900 Training Loss:0.003931\n",
            "58000 Training Loss:0.000018\n",
            "58100 Training Loss:0.000365\n",
            "58200 Training Loss:0.024801\n",
            "58300 Training Loss:0.000761\n",
            "58400 Training Loss:0.002863\n",
            "58500 Training Loss:0.000720\n",
            "58600 Training Loss:0.001163\n",
            "58700 Training Loss:0.014645\n",
            "58800 Training Loss:0.013296\n",
            "58900 Training Loss:0.000058\n",
            "59000 Training Loss:0.000594\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000851\n",
            "Epoch 22/24\n",
            "----------\n",
            "59100 Training Loss:0.004635\n",
            "59200 Training Loss:0.051605\n",
            "59300 Training Loss:0.001740\n",
            "59400 Training Loss:0.000408\n",
            "59500 Training Loss:0.018851\n",
            "59600 Training Loss:0.003122\n",
            "59700 Training Loss:0.000489\n",
            "59800 Training Loss:0.000002\n",
            "59900 Training Loss:0.001262\n",
            "60000 Training Loss:0.029176\n",
            "60100 Training Loss:0.005002\n",
            "60200 Training Loss:0.000113\n",
            "60300 Training Loss:0.000039\n",
            "60400 Training Loss:0.000063\n",
            "60500 Training Loss:0.000274\n",
            "60600 Training Loss:0.000484\n",
            "60700 Training Loss:0.005303\n",
            "60800 Training Loss:0.000100\n",
            "60900 Training Loss:0.000320\n",
            "61000 Training Loss:0.138937\n",
            "61100 Training Loss:0.000069\n",
            "61200 Training Loss:0.008515\n",
            "61300 Training Loss:0.003624\n",
            "61400 Training Loss:0.190720\n",
            "61500 Training Loss:0.000029\n",
            "61600 Training Loss:0.000233\n",
            "61700 Training Loss:0.011351\n",
            "val Loss: 0.0008 Acc: 0.9999\n",
            "Loss 0.000850\n",
            "Epoch 23/24\n",
            "----------\n",
            "61800 Training Loss:0.004295\n",
            "61900 Training Loss:0.000091\n",
            "62000 Training Loss:0.002248\n",
            "62100 Training Loss:0.000069\n",
            "62200 Training Loss:0.358544\n",
            "62300 Training Loss:0.006068\n",
            "62400 Training Loss:0.000002\n",
            "62500 Training Loss:0.002421\n",
            "62600 Training Loss:0.000138\n",
            "62700 Training Loss:0.052763\n",
            "62800 Training Loss:0.008056\n",
            "62900 Training Loss:0.042280\n",
            "63000 Training Loss:0.001922\n",
            "63100 Training Loss:0.000495\n",
            "63200 Training Loss:0.314576\n",
            "63300 Training Loss:0.000652\n",
            "63400 Training Loss:0.000122\n",
            "63500 Training Loss:0.039933\n",
            "63600 Training Loss:0.001115\n",
            "63700 Training Loss:0.002315\n",
            "63800 Training Loss:0.000001\n",
            "63900 Training Loss:0.000903\n",
            "64000 Training Loss:0.000233\n",
            "64100 Training Loss:0.001724\n",
            "64200 Training Loss:0.005381\n",
            "64300 Training Loss:0.071160\n",
            "64400 Training Loss:0.000193\n",
            "val Loss: 0.0009 Acc: 0.9999\n",
            "Loss 0.000850\n",
            "Epoch 24/24\n",
            "----------\n",
            "64500 Training Loss:0.009225\n",
            "64600 Training Loss:0.020276\n",
            "64700 Training Loss:0.003704\n",
            "64800 Training Loss:0.000151\n",
            "64900 Training Loss:0.000063\n",
            "65000 Training Loss:0.397792\n",
            "65100 Training Loss:0.004104\n",
            "65200 Training Loss:0.000013\n",
            "65300 Training Loss:0.038211\n",
            "65400 Training Loss:0.000050\n",
            "65500 Training Loss:0.000553\n",
            "65600 Training Loss:1.463594\n",
            "65700 Training Loss:0.012947\n",
            "65800 Training Loss:0.000078\n",
            "65900 Training Loss:0.001921\n",
            "66000 Training Loss:0.000007\n",
            "66100 Training Loss:0.158265\n",
            "66200 Training Loss:0.004269\n",
            "66300 Training Loss:0.018457\n",
            "66400 Training Loss:0.000231\n",
            "66500 Training Loss:0.003451\n",
            "66600 Training Loss:0.000452\n",
            "66700 Training Loss:0.000294\n",
            "66800 Training Loss:0.117778\n",
            "66900 Training Loss:0.003683\n",
            "67000 Training Loss:0.000087\n",
            "67100 Training Loss:0.002166\n",
            "val Loss: 0.0008 Acc: 0.9999\n",
            "Loss 0.000850\n",
            "Training complete in 56m 25s\n",
            "Best val Acc: 0.999888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMUPgy1oaXuq",
        "colab_type": "text"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKNjTdYRUu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using our model to predict the label\n",
        "def predict(image, model):\n",
        "    # Pass the image through our model\n",
        "    output = model.cpu().forward(image)\n",
        "    \n",
        "    # Reverse the log function in our output\n",
        "    output = torch.exp(output)\n",
        "    print(output)\n",
        "    \n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeCUunjRReey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Image\n",
        "def show_image(image):\n",
        "    # Convert image to numpy\n",
        "    image = image.numpy()\n",
        "    \n",
        "#     fig = plt.figure(figsize=(25, 4))\n",
        "#     plt.imshow(np.transpose(image[0], (1, 2, 0)))\n",
        "    # Un-normalize the image\n",
        "    image[0] = image[0] * 0.226 + 0.445\n",
        "    \n",
        "    # Print the image\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    plt.imshow(np.transpose(image[0], (1, 2, 0)))\n",
        "    plt.pause(0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUubbmlxRv3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process Image\n",
        "    image = process_image('data/val/free/76403.jpg')\n",
        "    # Give image to model to predict output\n",
        "    top_prob, top_class = predict(image, model_conv)\n",
        "    # Show the image\n",
        "    \n",
        "    \n",
        "    show_image(image)\n",
        "#     ax = plt.subplot(0, 1, i + 1)\n",
        "#     plt.tight_layout()\n",
        "    print('Is ' + ('full' if top_class else 'free') + ' with {:.2f}% certainty'.format(top_prob*100))\n",
        "#     ax.axis('off')\n",
        "    # Print the results\n",
        "#     print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of \", 'full' if top_class else 'free' )\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_k3UWI9RgyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, 23):\n",
        "    # Process Image\n",
        "    image = process_image(\"Toys/{}.jpg\".format(i))\n",
        "    # Give image to model to predict output\n",
        "    top_prob, top_class = predict(image, model_conv)\n",
        "    # Show the image\n",
        "    \n",
        "    \n",
        "    show_image(image)\n",
        "    ax = plt.subplot(1, 23, i + 1)\n",
        "#     plt.tight_layout()\n",
        "    ax.set_title('Is ' + ('full' if top_class else 'free') + ' with {:.2f}% certainty'.format(top_prob*100))\n",
        "    ax.axis('off')\n",
        "    # Print the results\n",
        "#     print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of \", 'full' if top_class else 'free' )\n",
        "\n",
        "    if i == 23:\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sb7ghelYapg",
        "colab_type": "text"
      },
      "source": [
        "# (Extra)File Management"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIr8YRg3N1mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PQ24HjYhvQ",
        "colab_type": "code",
        "outputId": "e418a859-24be-4f3d-fd2a-5b543706282d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#list\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'full.zip',\n",
              " 'dataset.zip',\n",
              " 'tempfree',\n",
              " 'data',\n",
              " 'adc.json',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFBsNBPVWhbj",
        "colab_type": "code",
        "outputId": "72ab6a67-062f-4e38-fd8b-01e5b7c7bb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define the name of the directory to be deleted\n",
        "path = \"dataset\"\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(path)\n",
        "except OSError:\n",
        "    print (\"Deletion of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully deleted the directory %s\" % path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully deleted the directory dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwMBuuGIb38k",
        "colab_type": "code",
        "outputId": "58e57895-2888-48ca-b112-fa0c63cb06b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# define the name of the directory to be created\n",
        "\n",
        "def createDir(path):\n",
        "  try:\n",
        "      os.makedirs(path)\n",
        "  except OSError:\n",
        "      print (\"Creation of the directory %s failed\" % path)\n",
        "  else:\n",
        "      print (\"Successfully created the directory %s\" % path)\n",
        "      \n",
        "      \n",
        "createDir('data/train/full');\n",
        "createDir('data/train/free');\n",
        "createDir('data/val/full');\n",
        "createDir('data/val/free');\n",
        "createDir('full');\n",
        "createDir('free');\n",
        "createDir('tempfree')\n",
        "createDir('temp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory data/train/full\n",
            "Successfully created the directory data/train/free\n",
            "Successfully created the directory data/val/full\n",
            "Successfully created the directory data/val/free\n",
            "Creation of the directory full failed\n",
            "Successfully created the directory free\n",
            "Successfully created the directory tempfree\n",
            "Creation of the directory temp failed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHriQFtH8KxT",
        "colab_type": "code",
        "outputId": "6f43d4af-b041-4f26-bd01-87d1b796218e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "createDir('temp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory temp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRVIMP6eW-Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete\n",
        "os.remove('full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oia6IvyZfTnX",
        "colab_type": "text"
      },
      "source": [
        "# Save model to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqX42d4eKFy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveToDrive(PATH):\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive \n",
        "  from google.colab import auth \n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  model_file = drive.CreateFile({'title' : PATH})                      \n",
        "  model_file.SetContentFile(PATH)                       \n",
        "  model_file.Upload()\n",
        "  \n",
        "  drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIAJlk27GTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveToDrive('squeezenet1_0.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7DM2KIcfl6i",
        "colab_type": "code",
        "outputId": "0f778a4d-8cfb-4eca-84f6-6d0bfd779cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.0MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTEZV7JUfose",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6s_byB2fyf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = drive.CreateFile({'title' : 'parking_model.pkl'})                      \n",
        "model_file.SetContentFile('parking_model.pkl')                       \n",
        "model_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE5vwi2Lf0d-",
        "colab_type": "code",
        "outputId": "b7cb97cf-6e82-41b7-b838-b9858147d496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1bhU3oQ6pmaLRM5GkeY2mcft-Az8oQ0LL'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXd7YLX847lt",
        "colab_type": "text"
      },
      "source": [
        "#Saving & Loading Model for Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swzc4nVzC7sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'parking_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfyr7pCO465P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fid = drive.ListFile({'q':\"title='parking_model.pkl'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('parking_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEDbxFD7XEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('parking_model.pkl'))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkHCINIE-qIi",
        "colab_type": "text"
      },
      "source": [
        "# Save/Load Entire Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq9QlcJZ-rxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_conv, 'squeezenet_t_v2.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBjCwAVnheUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveToDrive('squeezenet_t_v2.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Whn6ABp-vSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "model = torch.load('PATH')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paexgmtP_NkA",
        "colab_type": "text"
      },
      "source": [
        "# Saving & Loading a General Checkpoint for Inference and/or Resuming Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axwHEQ9h_O55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(epoch, model, optimizer, loss, modelName):\n",
        "  PATH = modelName + '{}'.format(epoch) + '.pt'\n",
        "  PATH2 = modelName + '{}'.format(epoch) + '.pkl'\n",
        "  torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss \n",
        "              }, PATH)\n",
        "  \n",
        "  convert2(PATH, PATH2)\n",
        "  return PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvdWwmkW_S99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(epoch, PATH):\n",
        "   \n",
        "  model, optimizer, criterion = DefineSqueeze(2, False)\n",
        "\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  print('Loss {:.6f}'.format(checkpoint['loss']))\n",
        "\n",
        "  model.train()\n",
        "  return model, optimizer, criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_iXgjvqMkfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveToDrive(save_checkpoint(epoch, model, optimizer, train_loss/len(train_loader.dataset), 'parking_densenet2_'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5f1uNDEugta",
        "colab_type": "code",
        "outputId": "366b1128-ca54-449c-f5ef-9cfd57c2f110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_conv, optimizer, criterion = load_checkpoint(1, 'squeezenet_tune_1.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 0.068585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXapd0cpK3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(PATH, DEST):\n",
        "  getFromDrive(PATH)\n",
        "  model_conv, optimizer, criterion = load_checkpoint(1, PATH)\n",
        "  torch.save(model_conv, DEST)\n",
        "  saveToDrive(DEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNiBmZKwCBTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert2(PATH, DEST):\n",
        "  model_conv, optimizer, criterion = load_checkpoint(1, PATH)\n",
        "  torch.save(model_conv, DEST)\n",
        "  saveToDrive(DEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB79yNYbpguB",
        "colab_type": "code",
        "outputId": "9f907c89-9953-44e6-8c1a-2bb0f0f8cbea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "convert('squeezenet_tune_4.pt', 'squeezenet_t_v6.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 0.077354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoNDQgwvtZQK",
        "colab_type": "text"
      },
      "source": [
        "# Import Model from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b_hUGeJBtiW1",
        "colab": {}
      },
      "source": [
        "def getFromDrive(name):\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  fid = drive.ListFile({'q':\"title='\"+ name +\"'\"}).GetList()[0]['id']\n",
        "  f = drive.CreateFile({'id': fid})\n",
        "  f.GetContentFile(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwYEXW2OuM3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getFromDrive('squeezenet_tune_0.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MfiC-qASm3t",
        "colab_type": "text"
      },
      "source": [
        "# Tunning dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxrO8VvXT2ML",
        "colab_type": "text"
      },
      "source": [
        "## Get from drive free, and full classes raw files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r-0w2xseQhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9u9XxuaSmTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='dataset.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('dataset.zip')\n",
        "\n",
        "!unzip dataset.zip\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='full.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('full.zip')\n",
        "!unzip full.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTCk-5ICV2GV",
        "colab_type": "text"
      },
      "source": [
        "## Full dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXjkU0om7x9F",
        "colab_type": "text"
      },
      "source": [
        "clean numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2S-sCLs7xUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DIR = 'full'\n",
        "TEMP = 'temp'\n",
        "i = 1\n",
        "for name in os.listdir(DIR):\n",
        "\t# if os.path.isfile(os.path.join(DIR, name)):\n",
        "\t# \tcontinue;\n",
        "\tdst = '{}'.format(i) + '.jpg'\n",
        "\tos.rename(os.path.join(DIR, name), os.path.join(TEMP, dst)) \n",
        "\ti += 1\n",
        "\n",
        "for name in os.listdir(DIR):\n",
        "\tos.remove(os.path.join(DIR, name))\n",
        "\n",
        "for name in os.listdir(TEMP):\n",
        "\tos.rename(os.path.join(TEMP, name), os.path.join(DIR, name))\n",
        "\n",
        "for name in os.listdir(TEMP):\n",
        "\tos.remove(os.path.join(TEMP, name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2_9VwyxUkcC",
        "colab_type": "text"
      },
      "source": [
        "*Blur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGKGYsQEUrFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading library \n",
        "import cv2 \n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "DIR = 'full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "count = size\n",
        "for i in range(1, size):\n",
        "\timg = cv2.imread('full/{}'.format(i) + '.jpg') \n",
        "\t  \n",
        "\t# Specify the kernel size. \n",
        "\t# The greater the size, the more the motion. \n",
        "\tkernel_size = random.randrange(8, 12)\n",
        "\n",
        "\t# Create the vertical kernel. \n",
        "\tkernel_v = np.zeros((kernel_size, kernel_size)) \n",
        "\t  \n",
        "\t# Create a copy of the same for creating the horizontal kernel. \n",
        "\tkernel_h = np.copy(kernel_v) \n",
        "\t  \n",
        "\t# Fill the middle row with ones. \n",
        "\tkernel_v[:, int((kernel_size - 1)/2)] = np.ones(kernel_size) \n",
        "\tkernel_h[int((kernel_size - 1)/2), :] = np.ones(kernel_size) \n",
        "\t  \n",
        "\t# Normalize. \n",
        "\tkernel_v /= kernel_size \n",
        "\tkernel_h /= kernel_size \n",
        "\t  \n",
        "\t# Apply the vertical kernel. \n",
        "\tvertical_mb = cv2.filter2D(img, -1, kernel_v) \n",
        "\t  \n",
        "\t# Apply the horizontal kernel. \n",
        "\thorizonal_mb = cv2.filter2D(img, -1, kernel_h) \n",
        "\t  \n",
        "\t# Save the outputs.\n",
        "\tcount += 1\n",
        "\tcv2.imwrite('full/' + str(count) + '.jpg', vertical_mb)\n",
        "\tcount += 1\n",
        "\tcv2.imwrite('full/' + str(count) + '.jpg', horizonal_mb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WtqjknUrjF",
        "colab_type": "text"
      },
      "source": [
        "*gamma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hnK50C0VPOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def adjust_gamma(image, gamma=1.0):\n",
        "\n",
        "  invGamma = 1.0 / gamma\n",
        "  table = np.array([((i / 255.0) ** invGamma) * 255\n",
        "    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "\n",
        "  return cv2.LUT(image, table)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        " \n",
        "import random\n",
        "import os\n",
        "\n",
        "DIR = 'full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "i = size + 1\n",
        "\n",
        "for name in os.listdir(DIR):\n",
        "    if not os.path.isfile(os.path.join(DIR, name)):\n",
        "      continue\n",
        "    original = cv2.imread(os.path.join(DIR, name), 1)\n",
        "    boolean = True if (random.randrange(0, 1)) else False\n",
        "\n",
        "    gamma = random.uniform(0.1, 0.4)\n",
        "    adjusted = adjust_gamma(original, gamma=gamma)\n",
        "    \n",
        "    changed_name = '{}'.format(i) + '.jpg'\n",
        "    cv2.imwrite(os.path.join(DIR, changed_name), adjusted)\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct5HmA5hVPpU",
        "colab_type": "text"
      },
      "source": [
        "*flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWU64My0VUnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DIR = 'full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "count = size + 1\n",
        "for i in range(1, size):\n",
        "\toriginalImage = cv2.imread('full/{}'.format(i) + '.jpg')\n",
        "\tflipVertical = cv2.flip(originalImage, 0)\n",
        "\tcv2.imwrite('full/' + str(count) + '.jpg', flipVertical)\n",
        "\tcount += 1\n",
        "\tflipHorizontal = cv2.flip(originalImage, 1)\n",
        "\tcv2.imwrite('full/' + str(count) + '.jpg', flipHorizontal)\n",
        "\tcount += 1\n",
        "\tflipBoth = cv2.flip(originalImage, -1)\n",
        "\tcv2.imwrite('full/' + str(count) + '.jpg', flipBoth)\n",
        "\tcount += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKQPZcaUVVAa",
        "colab_type": "text"
      },
      "source": [
        "## Free parking dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6cztfhuXXNk",
        "colab_type": "text"
      },
      "source": [
        "Initial crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_jPZQZIXWR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "RAW_FREE = 'dataset/initfree'\n",
        "i = 1\n",
        "for filename in os.listdir(RAW_FREE):\n",
        "  if not os.path.isfile(os.path.join(RAW_FREE, filename)):\n",
        "  \tcontinue\n",
        "\n",
        "  im = Image.open(os.path.join(RAW_FREE, filename))\n",
        "  im_crop = im.crop((78, 70, 625, 480))\n",
        "  im_crop.save('tempfree/{}'.format(i) + '.jpg')\n",
        "  i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eWHF2IHXX1x",
        "colab_type": "text"
      },
      "source": [
        "Crop with stride"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKTrzsvcVz_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "TEMP_FREE = 'tempfree'\n",
        "intervalX = 10\n",
        "intervalY = 20\n",
        "stride = 75\n",
        "count = 0\n",
        "\n",
        "for filename in os.listdir(TEMP_FREE):\n",
        "  if not os.path.isfile(os.path.join(TEMP_FREE, filename)):\n",
        "  \tcontinue\n",
        "    \n",
        "  img = cv2.imread(os.path.join(TEMP_FREE, filename), 1)\n",
        "\n",
        "  \n",
        "  # print img.shape\n",
        "\n",
        "  for i in range(0, img.shape[0] - stride, intervalX):\n",
        "    for j in range(0, img.shape[1] - stride, intervalY):\n",
        "        # print j\n",
        "        cropped_img = img[i:i + stride, j:j + stride]\n",
        "        count += 1\n",
        "        cv2.imwrite('free/' + str(count) + '.jpg', cropped_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqZRRwUgmRM5",
        "colab_type": "code",
        "outputId": "576f7a1e-9382-4b70-d86f-e342f595e19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "DIR = 'full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)\n",
        "\n",
        "DIR = 'free'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55153\n",
            "52224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL9kCTRrsAwT",
        "colab_type": "code",
        "outputId": "e6efa9cc-9dfa-4be5-b95a-e60e868736de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DIR = 'data/train/full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "length1 = size\n",
        "DIR = 'data/train/free'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "length2 = size\n",
        "DIR = 'data/val/full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "length3 = size\n",
        "DIR = 'data/val/free'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "length4 = size\n",
        "\n",
        "i = length1 + length2 + length3 + length4 + 1\n",
        "\n",
        "DIR = 'full'\n",
        "for filename in os.listdir(DIR):\n",
        "  if not os.path.isfile(os.path.join(DIR, filename)):\n",
        "  \tcontinue\n",
        "  \n",
        "  if (i % 15000) == 0:\n",
        "    print(i)\n",
        "  oldPath = os.path.join(DIR, filename);\n",
        "  newPath1 = 'data/train/full/%d.jpg' % (i,)\n",
        "  newPath3 = 'data/val/full/%d.jpg' % (i,)\n",
        "#   if random.randint(0, 1):\n",
        "#     continue\n",
        "    \n",
        "  if random.randint(0, 1) or random.randint(0, 1):\n",
        "    shutil.move(oldPath, newPath1)\n",
        "  else:\n",
        "    shutil.move(oldPath, newPath3)\n",
        "      \n",
        "  i += 1\n",
        "  \n",
        "DIR = 'free'\n",
        "for filename in os.listdir(DIR):\n",
        "  if not os.path.isfile(os.path.join(DIR, filename)):\n",
        "  \tcontinue\n",
        "  \n",
        "  if (i % 15000) == 0:\n",
        "    print(i)\n",
        "  oldPath = os.path.join(DIR, filename);\n",
        "  newPath2 = 'data/train/free/%d.jpg' % (i,)\n",
        "  newPath4 = 'data/val/free/%d.jpg' % (i,)\n",
        "#   if random.randint(0, 1):\n",
        "#     continue\n",
        "    \n",
        "  if random.randint(0, 1) or random.randint(0, 1):\n",
        "    shutil.move(oldPath, newPath2)\n",
        "  else:\n",
        "    shutil.move(oldPath, newPath4)\n",
        "      \n",
        "  i += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000\n",
            "30000\n",
            "45000\n",
            "60000\n",
            "75000\n",
            "90000\n",
            "105000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcQbHdIlqoNT",
        "colab_type": "code",
        "outputId": "7f10175a-2fe9-46bd-e736-73c4c3dc00e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "DIR = 'data/train/full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)\n",
        "\n",
        "DIR = 'data/train/free'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)\n",
        "\n",
        "DIR = 'data/val/full'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)\n",
        "\n",
        "DIR = 'data/val/free'\n",
        "size = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "print(size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41313\n",
            "39236\n",
            "13840\n",
            "12988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PrY2Kfmmi38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "a = numpy.array([[0, 1]])\n",
        " \n",
        "a = numpy.append(a, [[1, 5]], axis = 0)\n",
        "a = numpy.append(a, [[2, 0.5]], axis = 0)\n",
        "a = numpy.append(a, [[3, 3.5]], axis = 0)\n",
        "a = numpy.append(a, [[4, 1.5]], axis = 0)\n",
        "a = numpy.append(a, [[5, 0.05]], axis = 0)\n",
        "a = numpy.append(a, [[6, 0.1]], axis = 0)\n",
        "a = numpy.append(a, [[7, 0.2]], axis = 0)\n",
        "numpy.savetxt(\"foo.csv\", a, delimiter=\",\", fmt='%f')\n",
        "\n",
        "\n",
        "saveCSVToDrive(\"foo.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiT2P_iwnkFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveCSVToDrive(PATH):\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive \n",
        "  from google.colab import auth \n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  model_file = drive.CreateFile({'title' : PATH})                      \n",
        "  model_file.SetContentFile(PATH)                       \n",
        "  model_file.Upload()\n",
        "  \n",
        "  drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q8R1V38rqxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveCSV(PATH, numArray):\n",
        "  numpy.savetxt(PATH, numArray, delimiter=\",\", fmt='%f')\n",
        "  saveCSVToDrive(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}